{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# !pip uninstall httpx httpcore\n",
    "# !pip install --upgrade httpx httpcore"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:51:02.108884Z",
     "start_time": "2024-07-15T14:51:02.102649Z"
    }
   },
   "id": "51e5c917ece26947",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import builtins\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:53:37.528775Z",
     "start_time": "2024-07-15T14:53:36.747533Z"
    }
   },
   "id": "bccb927f719ec96b",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    open_api_key = config['open_api_key']\n",
    "language = 'Dutch'\n",
    "client = OpenAI(api_key=open_api_key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:53:37.581346Z",
     "start_time": "2024-07-15T14:53:37.530175Z"
    }
   },
   "id": "debe05cbb35421f9",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_sets_to_do(post_directory):\n",
    "    os.makedirs(os.path.join(language, 'Vocabulary', post_directory), exist_ok = True)\n",
    "    donesets = os.listdir(os.path.join(language, 'Vocabulary', post_directory))\n",
    "    print('Done:', donesets)\n",
    "    if '.DS_Store' in donesets:\n",
    "        donesets.remove('.DS_Store')\n",
    "    allsets = os.listdir(os.path.join(language, 'Vocabulary', 'split_sets'))\n",
    "    notdonesets = [i for i in allsets if not i in donesets]\n",
    "    todosets = notdonesets#['900-1000.csv']\n",
    "    if '.DS_Store' in donesets:\n",
    "        todosets.remove('.DS_Store')\n",
    "    print('To Do:', todosets)\n",
    "    return todosets\n",
    "# todosets = get_sets_to_do('Split_Sets','ChatGPT_Sets')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:53:38.400710Z",
     "start_time": "2024-07-15T14:53:38.391318Z"
    }
   },
   "id": "324822c4ae6b9b29",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "frequencydf = pd.read_csv(os.path.join('Frequency Lists', language, 'Clean.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:53:38.853217Z",
     "start_time": "2024-07-15T14:53:38.837464Z"
    }
   },
   "id": "631a60b4b700101c",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "697070e6257d63fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "VOCABULARY SPLIT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d2c9d93cd2002f0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['Dutch', 'POS']\n",
      "remainder= 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "def split_into_studysets(frequencydf, language, initial_splitsize=100, new_splitsize=250):\n",
    "    os.makedirs(os.path.join(language, 'Vocabulary', 'Split_Sets'), exist_ok=True)\n",
    "    columns = [language]\n",
    "    if 'POS' in frequencydf.columns:\n",
    "        columns.append('POS')\n",
    "    if 'Translation' in frequencydf.columns:\n",
    "        columns.append('Translation')\n",
    "    if 'English' in frequencydf.columns:\n",
    "        frequencydf.rename(columns={'English': 'Translation'}, inplace=True)\n",
    "        columns.append('Translation')\n",
    "    if 'lemma' in frequencydf.columns:\n",
    "        columns.append('show')\n",
    "        columns.append('lemma')\n",
    "    print('columns:', columns)\n",
    "    \n",
    "    total_rows = len(frequencydf)\n",
    "    i = 0\n",
    "    splitsize = initial_splitsize\n",
    "    \n",
    "    while i * splitsize < total_rows:\n",
    "        if i * splitsize >= 1000:\n",
    "            splitsize = new_splitsize\n",
    "            start_index = 1000 + (i - 10) * new_splitsize  # Adjust start index for new splitsize\n",
    "        else:\n",
    "            start_index = i * splitsize\n",
    "        \n",
    "        end_index = min(start_index + splitsize, total_rows)\n",
    "        subdf = frequencydf[start_index:end_index][columns]\n",
    "        subdf.to_csv(language + '/Vocabulary/Split_Sets/' + str(start_index) + '-' + str(end_index) + '.csv')\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    remainder = total_rows % splitsize\n",
    "    print('remainder=', remainder)\n",
    "    if remainder > 0:\n",
    "        remaindersubdf = frequencydf[-remainder:][columns]\n",
    "        remaindersubdf.to_csv(language + '/Vocabulary/Split_Sets/' + 'Remainder.csv')\n",
    "\n",
    "    return subdf\n",
    "\n",
    "# Example usage\n",
    "df = split_into_studysets(frequencydf, language=language)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:49:55.090450Z",
     "start_time": "2024-07-15T14:49:55.055607Z"
    }
   },
   "id": "58c4b9f973741e8e",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you only want to do a subset of files for time purposes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87b4b10f96a58987"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "selected_files = ['800-900.csv', '600-700.csv']#, '700-800.csv', '900-1000.csv', '500-600.csv']\n",
    "\n",
    "def move_unselected_files(language, selected_files):\n",
    "    # Create directory for spare sets\n",
    "    spare_split_sets_dir = os.path.join(language, 'Vocabulary', 'Spare_Split_Sets')\n",
    "    os.makedirs(spare_split_sets_dir, exist_ok=True)\n",
    "\n",
    "    split_sets_dir = os.path.join(language, 'Vocabulary', 'Split_Sets')\n",
    "    all_files = os.listdir(split_sets_dir)\n",
    "    selected_files_set = set(selected_files)\n",
    "\n",
    "    # Move files not in selected_files to the spare sets directory\n",
    "    for file_name in all_files:\n",
    "        if file_name not in selected_files_set:\n",
    "            os.rename(\n",
    "                os.path.join(split_sets_dir, file_name),\n",
    "                os.path.join(spare_split_sets_dir, file_name)\n",
    "            )\n",
    "  # example of selected files\n",
    "move_unselected_files(language, selected_files)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:49:56.109434Z",
     "start_time": "2024-07-15T14:49:56.106729Z"
    }
   },
   "id": "8352a6d18e01aa0c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "CHATGPT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5484fa0c59fef9b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ['.DS_Store', '800-900.csv', '100-200.csv', '600-700.csv', '700-800.csv', '0-100.csv', '300-400.csv', '900-1000.csv', '400-500.csv', '500-600.csv', '200-300.csv']\n",
      "To Do: []\n"
     ]
    }
   ],
   "source": [
    "CHATGPT_todosets = get_sets_to_do('ChatGPT_Sets')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:49:57.052682Z",
     "start_time": "2024-07-15T14:49:57.046268Z"
    }
   },
   "id": "c117c00eba8178c0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_sentence_in_target_language(variable_word, POS, words_to_include, model = 'gpt-4o-2024-05-13', tenses = ['present', 'future', 'past']):\n",
    "    \"\"\"\n",
    "    Generate a sentence in Russian using a specific word and part of speech, with words from a limited vocabulary, along with its English translation.\n",
    "\n",
    "    Parameters:\n",
    "    variable_word (str): The word to include in the sentence.\n",
    "    POS (str): The part of speech the word should operate as.\n",
    "    words_to_include (tuple): A list of words to try to include, and how many\n",
    "    model (str): The model to use for generating the sentence (default is 'gpt-4o-2024-05-13').\n",
    "    \n",
    "    # vocabulary (list): A list of words to use in the sentence.\n",
    "    # tenses (list)\n",
    "\n",
    "    Returns:\n",
    "    str: A sentence in Russian and its English translation, separated by a newline.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(variable_word, POS)\n",
    "    words_to_include = list(words_to_include[0].sample(words_to_include[1], replace=False))\n",
    "    print(words_to_include)\n",
    "    # vocabulary = vocabulary\n",
    "    # vocabulary_str = ', '.join(vocabulary)\n",
    "    prompt = (\n",
    "              # f\"Use only the following Russian words: {vocabulary_str}. \"\n",
    "        \n",
    "              f\"Create a simple sentence in f{language} using basic vocabulary and containing the word '{variable_word}' \"\n",
    "              f\"operating as a {POS} part of speech. Also, provide the English translation of the sentence separated by a newline.\"\n",
    "              f\"Try to include the following words in the sentence: {words_to_include}\"\n",
    "              # f\"Use only the following tenses: {tenses}. \"\n",
    "              )\n",
    "\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=50,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "\n",
    "        # Extract and return the output\n",
    "        output_message = response.choices[0].message.content.strip()\n",
    "        return output_message\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "    # Extract and return the output\n",
    "    output_message = response.choices[0].message.content.strip()\n",
    "    return output_message"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:27:51.427834Z",
     "start_time": "2024-07-13T13:27:51.416304Z"
    }
   },
   "id": "6300157e037e763a",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoop noun\n",
      "['ligt', 'open']\n",
      "De hoop ligt open voor iedereen.  \n",
      "The hope is open for everyone.\n",
      "wou verb\n",
      "['verder', 'blijft']\n",
      "Ik wou verder gaan, maar hij blijft hier.\n",
      "I wanted to go further, but he stays here.\n",
      "vermoord verb\n",
      "['werken', 'alsof']\n",
      "Hij werkt alsof hij vermoord is.\n",
      "\n",
      "He works as if he has been murdered.\n",
      "elke pronoun\n",
      "['pijn', 'gehad']\n",
      "Elke keer heb ik pijn gehad.\n",
      "Every time I have had pain.\n"
     ]
    }
   ],
   "source": [
    "#TEST THE API\n",
    "for index, row in frequencydf.iloc[304:308].iterrows():\n",
    "    sentence = generate_sentence_in_target_language(row[language], row.POS, (frequencydf.iloc[300:400][language], 2))\n",
    "    print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:25:04.748326Z",
     "start_time": "2024-07-13T13:25:01.645342Z"
    }
   },
   "id": "f46e7071d2767627",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def chatonset(s_set_df, set_name, n = 2):\n",
    "    words_to_include = (s_set_df[language], n)\n",
    "    s_set_df['ChatGPT_Sentence'] = s_set_df.apply(lambda row: generate_sentence_in_target_language(row[language], row['POS'], words_to_include), axis = 1)\n",
    "    s_set_df.to_csv(os.path.join(language, 'Vocabulary','ChatGPT_Sets', set_name))\n",
    "    return s_set_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:27:54.703203Z",
     "start_time": "2024-07-13T13:27:54.698761Z"
    }
   },
   "id": "initial_id",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def do_all_sets(post_directory, func, language = language):\n",
    "    os.makedirs(os.path.join(language, 'Vocabulary', post_directory), exist_ok = True)\n",
    "    allsets = os.listdir(os.path.join(language, 'Vocabulary', 'split_sets'))\n",
    "    todosets = get_sets_to_do(post_directory)\n",
    "    for s_set in todosets:\n",
    "        if s_set[0] != '.':\n",
    "        # # if s_set == '500-600.csv':\n",
    "        #     # print(s_set)\n",
    "            s_set_df = pd.read_csv(\n",
    "                os.path.join(language, 'Vocabulary', 'split_sets', s_set)\n",
    "            )\n",
    "            print(s_set_df)\n",
    "            print(s_set)\n",
    "            func(s_set_df, s_set)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:27:55.383496Z",
     "start_time": "2024-07-13T13:27:55.373427Z"
    }
   },
   "id": "431870784f63c5e0",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: []\n",
      "To Do: ['800-900.csv', '600-700.csv']\n",
      "    Unnamed: 0      Dutch        POS\n",
      "0          800      geest       noun\n",
      "1          801     gingen       verb\n",
      "2          802     straat       noun\n",
      "3          803    slechts     adverb\n",
      "4          804  verkeerde  adjective\n",
      "..         ...        ...        ...\n",
      "95         895    schelen       verb\n",
      "96         896      kaart       noun\n",
      "97         897        rij       noun\n",
      "98         898        bal       noun\n",
      "99         899     werkte       verb\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "800-900.csv\n",
      "geest noun\n",
      "['wonen', 'stomme']\n",
      "gingen verb\n",
      "['geraakt', 'bekend']\n",
      "straat noun\n",
      "['bestaat', 'zak']\n",
      "slechts adverb\n",
      "['begonnen', 'meeste']\n",
      "verkeerde adjective\n",
      "['wegwezen', 'nadat']\n",
      "slaan verb\n",
      "['bekend', 'geboren']\n",
      "FBI FBI\n",
      "['feest', 'liefje']\n",
      "afgelopen adjective\n",
      "['zolang', 'schelen']\n",
      "hotel noun\n",
      "['keuze', 'feest']\n",
      "bekend adjective\n",
      "['raad', 'stom']\n",
      "ene one\n",
      "['koud', 'mocht']\n",
      "ruimte noun\n",
      "['geraakt', 'www']\n",
      "lange adjective\n",
      "['bal', 'totdat']\n",
      "trouwens adverb\n",
      "['betaald', 'stomme']\n",
      "feest noun\n",
      "['regel', 'wegwezen']\n",
      "vliegen verb\n",
      "['honger', 'bewijzen']\n",
      "boot noun\n",
      "['red', 'ene']\n",
      "meester noun\n",
      "['geprobeerd', 'situatie']\n",
      "doel noun\n",
      "['gaten', 'kaart']\n",
      "zolang conjunction\n",
      "['ruimte', 'kaart']\n",
      "regels noun\n",
      "['honger', 'www']\n",
      "stomme noun\n",
      "['verliefd', 'gevaarlijk']\n",
      "begonnen verb\n",
      "['koud', 'mocht']\n",
      "zak noun\n",
      "['lange', 'koud']\n",
      "absoluut adverb\n",
      "['woont', 'totdat']\n",
      "spreek adjective\n",
      "['ruimte', 'kleren']\n",
      "stom adjective\n",
      "['macht', 'feest']\n",
      "bestaat verb\n",
      "['herinneren', 'stomme']\n",
      "welk conjunction\n",
      "['macht', 'zak']\n",
      "gevaarlijk adjective\n",
      "['afgelopen', 'goedemorgen']\n",
      "jawel interjection\n",
      "['kleren', 'werkte']\n",
      "mocht verb\n",
      "['gaten', 'vliegen']\n",
      "goedemorgen interjection\n",
      "['raar', 'gebracht']\n",
      "wilden verb\n",
      "['slaan', 'verkopen']\n",
      "erger adjective\n",
      "['lieve', 'gaten']\n",
      "vreselijk adjective\n",
      "['nadat', 'meeste']\n",
      "zodra conjunction\n",
      "['ene', 'FBI']\n",
      "geraakt adjective\n",
      "['raken', 'red']\n",
      "nadat conjunction\n",
      "['geboren', 'gedacht']\n",
      "vertrouw trust\n",
      "['zak', 'vertrouw']\n",
      "kolonel noun\n",
      "['zover', 'keuze']\n",
      "voelde verb\n",
      "['vertrouw', 'erover']\n",
      "kleren noun\n",
      "['absoluut', 'macht']\n",
      "rug noun\n",
      "['bewijzen', 'bal']\n",
      "naast adjective\n",
      "['bestaat', 'werkte']\n",
      "totdat conjunction\n",
      "['lul', 'goedemorgen']\n",
      "verliefd adjective\n",
      "['voorstellen', 'wegwezen']\n",
      "lukt verb\n",
      "['mocht', 'geprobeerd']\n",
      "wonen verb\n",
      "['bestaat', 'geprobeerd']\n",
      "lieve noun\n",
      "['bal', 'bestaat']\n",
      "gaten noun\n",
      "['vorige', 'slaan']\n",
      "raar adjective\n",
      "['schrijven', 'regel']\n",
      "geprobeerd verb\n",
      "['lul', 'erger']\n",
      "geleerd adjective\n",
      "['slaan', 'lul']\n",
      "erover about it\n",
      "['trouwens', 'schrijven']\n",
      "raad noun\n",
      "['geweldige', 'werkte']\n",
      "volg verb\n",
      "['drugs', 'zolang']\n",
      "verkopen verb\n",
      "['gebouw', 'situatie']\n",
      "geweldige adjective\n",
      "['slaan', 'begonnen']\n",
      "zover adverb\n",
      "['straat', 'rij']\n",
      "red adjective\n",
      "['wonen', 'jawel']\n",
      "woont verb\n",
      "['geboren', 'raar']\n",
      "Amerika noun\n",
      "['vertrouw', 'hotel']\n",
      "lul noun\n",
      "['werkte', 'raad']\n",
      "gedacht verb\n",
      "['naast', 'hotel']\n",
      "bewijzen verb\n",
      "['stomme', 'betaald']\n",
      "prijs noun\n",
      "['dragen', 'straat']\n",
      "www www\n",
      "['stom', 'verkeerde']\n",
      "raken verb\n",
      "['mocht', 'raken']\n",
      "voorstellen verb\n",
      "['afgelopen', 'erover']\n",
      "vorige adjective\n",
      "['gebracht', 'schrijven']\n",
      "regel noun\n",
      "['red', 'drugs']\n",
      "schrijven verb\n",
      "['totdat', 'voelde']\n",
      "rot noun\n",
      "['zolang', 'geraakt']\n",
      "gebouw noun\n",
      "['zolang', 'zak']\n",
      "trekken verb\n",
      "['liefje', 'raken']\n",
      "herinneren verb\n",
      "['lange', 'gebracht']\n",
      "dansen noun\n",
      "['stomme', 'bestaat']\n",
      "gebracht verb\n",
      "['totdat', 'jawel']\n",
      "meeste most\n",
      "['gefeliciteerd', 'ruimte']\n",
      "koud adjective\n",
      "['gefeliciteerd', 'raken']\n",
      "jammer adjective\n",
      "['liefje', 'wegwezen']\n",
      "wegwezen verb\n",
      "['lul', 'regels']\n",
      "macht noun\n",
      "['FBI', 'betaald']\n",
      "drugs noun\n",
      "['FBI', 'schrijven']\n",
      "geboren adjective\n",
      "['bekend', 'lukt']\n",
      "dragen verb\n",
      "['schrijven', 'goedemorgen']\n",
      "keuze noun\n",
      "['vliegen', 'begonnen']\n",
      "gefeliciteerd interjection\n",
      "['gaten', 'meeste']\n",
      "situatie noun\n",
      "['raar', 'naast']\n",
      "missen verb\n",
      "['gaten', 'woont']\n",
      "honger noun\n",
      "['absoluut', 'duurt']\n",
      "betaald adjective\n",
      "['woont', 'boot']\n",
      "liefje noun\n",
      "['trekken', 'trouwens']\n",
      "duurt verb\n",
      "['schelen', 'FBI']\n",
      "schelen verb\n",
      "['zak', 'missen']\n",
      "kaart noun\n",
      "['duurt', 'gebracht']\n",
      "rij noun\n",
      "['regel', 'ene']\n",
      "bal noun\n",
      "['zak', 'lul']\n",
      "werkte verb\n",
      "['betaald', 'regels']\n",
      "    Unnamed: 0      Dutch        POS\n",
      "0          600      nieuw  adjective\n",
      "1          601        elk    pronoun\n",
      "2          602       erin      in it\n",
      "3          603  ontmoeten       verb\n",
      "4          604    vechten       verb\n",
      "..         ...        ...        ...\n",
      "95         695       trek       noun\n",
      "96         696       meen       verb\n",
      "97         697     enkele     adverb\n",
      "98         698   getrouwd  adjective\n",
      "99         699   gevraagd  adjective\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "600-700.csv\n",
      "nieuw adjective\n",
      "['spel', 'perfect']\n",
      "elk pronoun\n",
      "['perfect', 'ziek']\n",
      "erin in it\n",
      "['noemen', 'trek']\n",
      "ontmoeten verb\n",
      "['eh', 'daarmee']\n",
      "vechten verb\n",
      "['eindelijk', 'stap']\n",
      "voorzichtig adjective\n",
      "['gesproken', 'voorzichtig']\n",
      "geworden verb\n",
      "['vechten', 'idioot']\n",
      "enkel adjective\n",
      "['perfect', 'verwacht']\n",
      "kwijt adjective\n",
      "['seks', 'kracht']\n",
      "noemen verb\n",
      "['stuur', 'ontmoeten']\n",
      "valt verb\n",
      "['leg', 'zichzelf']\n",
      "prachtig adjective\n",
      "['schieten', 'ervoor']\n",
      "rijden verb\n",
      "['ontmoeten', 'ervoor']\n",
      "zin noun\n",
      "['verkeerd', 'meisjes']\n",
      "hield verb\n",
      "['gevangenis', 'shit']\n",
      "daarna adverb\n",
      "['nieuw', 'kopen']\n",
      "mens noun\n",
      "['slechte', 'beloof']\n",
      "schieten verb\n",
      "['slechte', 'plezier']\n",
      "grappig adjective\n",
      "['winnen', 'daarmee']\n",
      "stap noun\n",
      "['daarna', 'zin']\n",
      "zichzelf pronoun\n",
      "['nam', 'goeie']\n",
      "kantoor noun\n",
      "['frank', 'gegaan']\n",
      "wapens noun\n",
      "['degene', 'minder']\n",
      "normaal adjective\n",
      "['meen', 'seks']\n",
      "slechte adjective\n",
      "['pardon', 'geworden']\n",
      "maakte verb\n",
      "['ontmoeten', 'enkel']\n",
      "moord noun\n",
      "['beloof', 'geworden']\n",
      "gebeld verb\n",
      "['zomaar', 'koffie']\n",
      "ervoor before\n",
      "['kracht', 'heer']\n",
      "ten at\n",
      "['daarmee', 'gebruik']\n",
      "heer noun\n",
      "['goeie', 'beschermen']\n",
      "loopt verb\n",
      "['lucht', 'acht']\n",
      "einde noun\n",
      "['daarna', 'gang']\n",
      "gegaan verb\n",
      "['daarmee', 'valt']\n",
      "gang noun\n",
      "['idioot', 'koffie']\n",
      "vertelde verb\n",
      "['grond', 'contact']\n",
      "spel noun\n",
      "['kwijt', 'ontmoeten']\n",
      "informatie noun\n",
      "['beloof', 'gesproken']\n",
      "frank frank\n",
      "['winnen', 'ten']\n",
      "dames adjective\n",
      "['getrouwd', 'nam']\n",
      "naartoe preposition\n",
      "['grond', 'verkeerd']\n",
      "allebei adjective\n",
      "['erbij', 'dames']\n",
      "leg noun\n",
      "['pardon', 'trek']\n",
      "acht noun\n",
      "['gang', 'degene']\n",
      "pap noun\n",
      "['kwijt', 'eh']\n",
      "seks noun\n",
      "['ziek', 'plezier']\n",
      "minder adjective\n",
      "['hoezo', 'eh']\n",
      "gevoel noun\n",
      "['idioot', 'meen']\n",
      "trouwen verb\n",
      "['seks', 'wapens']\n",
      "nogal adverb\n",
      "['pap', 'loopt']\n",
      "eh er\n",
      "['pardon', 'lucht']\n",
      "voelen verb\n",
      "['informatie', 'persoon']\n",
      "begint verb\n",
      "['noemen', 'grappig']\n",
      "plezier noun\n",
      "['daarmee', 'omhoog']\n",
      "meisjes adjective\n",
      "['noemen', 'allebei']\n",
      "stuur noun\n",
      "['gang', 'erbij']\n",
      "foto noun\n",
      "['nogal', 'herinner']\n",
      "vreemd adjective\n",
      "['slechte', 'elk']\n",
      "zomaar adverb\n",
      "['einde', 'grond']\n",
      "verkeerd adjective\n",
      "['moord', 'enkele']\n",
      "zeven verb\n",
      "['vreemd', 'plezier']\n",
      "lucht noun\n",
      "['trek', 'nieuw']\n",
      "grond noun\n",
      "['goeie', 'meisjes']\n",
      "leeft verb\n",
      "['frank', 'idioot']\n",
      "nam verb\n",
      "['vreemd', 'wapens']\n",
      "pardon interjection\n",
      "['nieuw', 'rijden']\n",
      "verwacht verb\n",
      "['leeft', 'acht']\n",
      "kopen verb\n",
      "['wapens', 'contact']\n",
      "koffie noun\n",
      "['nogal', 'begint']\n",
      "onderzoek noun\n",
      "['aarde', 'elk']\n",
      "gesproken verb\n",
      "['nogal', 'noemen']\n",
      "herinner verb\n",
      "['dames', 'idioot']\n",
      "idioot noun\n",
      "['verwacht', 'beschermen']\n",
      "ziekenhuis noun\n",
      "['pap', 'persoon']\n",
      "daarmee adverb\n",
      "['goeie', 'leeft']\n",
      "shit shit\n",
      "['beloof', 'verwacht']\n",
      "eindelijk adverb\n",
      "['acht', 'verkeerd']\n",
      "perfect adjective\n",
      "['winnen', 'geworden']\n",
      "goeie good\n",
      "['erbij', 'trouwen']\n",
      "gisteren adverb\n",
      "['nieuw', 'zeven']\n",
      "aarde noun\n",
      "['persoon', 'ziek']\n",
      "contact noun\n",
      "['ten', 'meen']\n",
      "zus noun\n",
      "['trek', 'omhoog']\n",
      "erbij there\n",
      "['kwijt', 'gevoel']\n",
      "beschermen verb\n",
      "['heer', 'nogal']\n",
      "gevangenis noun\n",
      "['informatie', 'nam']\n",
      "persoon noun\n",
      "['mens', 'koffie']\n",
      "winnen verb\n",
      "['kracht', 'valt']\n",
      "kracht noun\n",
      "['pap', 'gang']\n",
      "ziek adjective\n",
      "['elk', 'kantoor']\n",
      "omhoog adverb\n",
      "['lucht', 'elk']\n",
      "beloof verb\n",
      "['ten', 'rijden']\n",
      "gebruik noun\n",
      "['daarmee', 'gebruik']\n",
      "hoezo adverb\n",
      "['loopt', 'idioot']\n",
      "degene the one\n",
      "['ziekenhuis', 'zeven']\n",
      "trek noun\n",
      "['voorzichtig', 'rijden']\n",
      "meen verb\n",
      "['pap', 'verwacht']\n",
      "enkele adverb\n",
      "['goeie', 'frank']\n",
      "getrouwd adjective\n",
      "['enkel', 'ervoor']\n",
      "gevraagd adjective\n",
      "['zus', 'mens']\n"
     ]
    }
   ],
   "source": [
    "do_all_sets('ChatGPT_Sets', chatonset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:30:22.188038Z",
     "start_time": "2024-07-13T13:27:56.163444Z"
    }
   },
   "id": "4803e43262230313",
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "source": [
    "ADD TRANSLATION INFORMATION:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c95b5e763d556a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:39:00.181315Z",
     "start_time": "2024-07-13T13:38:59.829400Z"
    }
   },
   "id": "4b30611e85cc8e7e",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_set_translation_information(s_set_df, set_name, code = 'nl'):\n",
    "    # Apply the translation\n",
    "    s_set_df['Translation'] = s_set_df.apply(\n",
    "        lambda row: GoogleTranslator(source= code, target='en').translate(row[language]), axis=1\n",
    "    )\n",
    "\n",
    "    # Save to CSV\n",
    "    s_set_df.to_csv(os.path.join(language, 'Vocabulary/Translated Sets', set_name), index=False)\n",
    "    return s_set_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:48:58.823540Z",
     "start_time": "2024-07-13T13:48:58.818538Z"
    }
   },
   "id": "12e9fbf3edff6829",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: []\n",
      "To Do: ['800-900.csv', '600-700.csv']\n"
     ]
    }
   ],
   "source": [
    "translation_todosets = get_sets_to_do('Translated Sets')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:48:59.929473Z",
     "start_time": "2024-07-13T13:48:59.918501Z"
    }
   },
   "id": "7d085b8180f44d76",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800-900.csv\n",
      "Done: []\n",
      "To Do: ['800-900.csv', '600-700.csv']\n",
      "    Unnamed: 0      Dutch        POS\n",
      "0          800      geest       noun\n",
      "1          801     gingen       verb\n",
      "2          802     straat       noun\n",
      "3          803    slechts     adverb\n",
      "4          804  verkeerde  adjective\n",
      "..         ...        ...        ...\n",
      "95         895    schelen       verb\n",
      "96         896      kaart       noun\n",
      "97         897        rij       noun\n",
      "98         898        bal       noun\n",
      "99         899     werkte       verb\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "800-900.csv\n",
      "    Unnamed: 0      Dutch        POS\n",
      "0          600      nieuw  adjective\n",
      "1          601        elk    pronoun\n",
      "2          602       erin      in it\n",
      "3          603  ontmoeten       verb\n",
      "4          604    vechten       verb\n",
      "..         ...        ...        ...\n",
      "95         695       trek       noun\n",
      "96         696       meen       verb\n",
      "97         697     enkele     adverb\n",
      "98         698   getrouwd  adjective\n",
      "99         699   gevraagd  adjective\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "600-700.csv\n",
      "600-700.csv\n",
      "Done: ['800-900.csv', '600-700.csv']\n",
      "To Do: []\n"
     ]
    }
   ],
   "source": [
    "for set in translation_todosets:\n",
    "    print(set)\n",
    "    do_all_sets('Translated Sets', add_set_translation_information)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:49:29.687996Z",
     "start_time": "2024-07-13T13:49:00.403387Z"
    }
   },
   "id": "25893c8ba5ba6b07",
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make into Quizlet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78468a35bd76d7aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_quizlet_set(set_name):\n",
    "    df = pd.read_csv(os.path.join(language, 'Vocabulary', 'ChatGPT_Sets', set_name))\n",
    "    transdf = pd.read_csv(os.path.join(language, 'Vocabulary', 'Translated Sets', set_name))\n",
    "\n",
    "    df['ChatGPT_Sentence'] = df['ChatGPT_Sentence'].apply(lambda x: re.sub(r'\\n+', '\\n', x))\n",
    "\n",
    "    # Removing text within parentheses that start with 'see'\n",
    "    df['ChatGPT_Sentence'] = df['ChatGPT_Sentence'].str.replace(r'\\(see[^)]*\\)', '', regex=True)\n",
    "    # Removing any extra spaces that might result from the replacement\n",
    "    df['ChatGPT_Sentence'] = df['ChatGPT_Sentence'].str.strip()\n",
    "    df['quizlet'] = transdf['POS'] + ' : ' + '*' + transdf['Translation'] + '*' + '\\n' + df['ChatGPT_Sentence']\n",
    "\n",
    "    df = df[[language, 'quizlet']]\n",
    "    os.makedirs(os.path.join(language, 'Vocabulary', 'Quizlet Sets'), exist_ok=True)\n",
    "    output_path = os.path.join(language, 'Vocabulary', 'Quizlet Sets', set_name.replace('.csv', '.txt'))\n",
    "\n",
    "    # Saving the data to a tab-separated text file with 3 lines between each row\n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for index, row in df.iterrows():\n",
    "            outfile.write(f\"{row[language]}\\t{row['quizlet']}\\n\\n\\n\")\n",
    "\n",
    "    print(f\"Text file saved to {output_path}\")\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T15:03:00.877455Z",
     "start_time": "2024-07-13T15:03:00.874620Z"
    }
   },
   "id": "6f5dba1a4a2efcc8",
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#test make_quizlet_set('800-900.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T15:03:01.409715Z",
     "start_time": "2024-07-13T15:03:01.403766Z"
    }
   },
   "id": "5546d1cab8dd4609",
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'600-700.csv', '800-900.csv'}"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builtin_set = builtins.set\n",
    "a = builtin_set(os.listdir(os.path.join(language, 'Vocabulary', 'ChatGPT_Sets')))\n",
    "b = builtin_set(os.listdir(os.path.join(language, 'Vocabulary', 'Translated Sets')))\n",
    "quizlet_todosets = a.intersection(b)\n",
    "quizlet_todosets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T15:04:38.994863Z",
     "start_time": "2024-07-13T15:04:38.990956Z"
    }
   },
   "id": "f317b89326596dd2",
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file saved to Dutch/Vocabulary/Quizlet Sets/800-900.txt\n",
      "Text file saved to Dutch/Vocabulary/Quizlet Sets/600-700.txt\n"
     ]
    }
   ],
   "source": [
    "for s_set in quizlet_todosets:\n",
    "    make_quizlet_set(s_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T15:04:40.031108Z",
     "start_time": "2024-07-13T15:04:40.003909Z"
    }
   },
   "id": "82be2d1cb2d9c891",
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def makequizlet_step2(input_file):\n",
    "#     output_file = input_file \n",
    "#     with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "#         reader = csv.reader(infile)\n",
    "#         rows = list(reader)\n",
    "# \n",
    "#     # Write the output CSV file with extra newlines\n",
    "#     with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "#         writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n",
    "#         for row in rows:\n",
    "#             writer.writerow(row)\n",
    "#             writer.writerow([])  # Add a blank row\n",
    "#             writer.writerow([])  # Add a blank row\n",
    "#             writer.writerow([])\n",
    "# \n",
    "#     print(f\"Modified CSV file saved as {output_file}\")\n",
    "#     \n",
    "# for file in os.listdir(os.path.join(language, 'Vocabulary/Quizlet Sets')):\n",
    "#     if file[0] != '.':\n",
    "#         print(file)\n",
    "#         makequizlet_step2(os.path.join(language, 'Vocabulary/Quizlet Sets/' + file))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff44b0def52b0a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import csv\n",
    "# def make_quizlet_set(set_name):\n",
    "#     df = pd.read_csv(os.path.join(language, 'Vocabulary', 'ChatGPT_Sets', set_name))\n",
    "#     transdf = pd.read_csv(os.path.join(language, 'Vocabulary', 'Translated Sets', set_name))\n",
    "#     \n",
    "#     df['ChatGPT_Sentence'] = df['ChatGPT_Sentence'].apply(lambda x: re.sub(r'\\n+', '\\n', x))\n",
    "#     \n",
    "#     # Removing text within parentheses that start with 'see'\n",
    "#     df['ChatGPT_Sentence'] = df['ChatGPT_Sentence'].str.replace(r'\\(see[^)]*\\)', '', regex=True)   \n",
    "#     # Removing any extra spaces that might result from the replacement\n",
    "#     df['ChatGPT_Sentence'] = df['ChatGPT_Sentence'].str.strip()\n",
    "#     df['quizlet'] = transdf['POS'] + ' : ' + '*' + transdf['Translation'] + '*' + '\\n\\n' + df['ChatGPT_Sentence']\n",
    "# \n",
    "# \n",
    "#     df = df[[language, 'quizlet']]\n",
    "#     os.makedirs(os.path.join(language, 'Vocabulary', 'Quizlet Sets'), exist_ok = True)\n",
    "#     output_path = os.path.join(language, 'Vocabulary', 'Quizlet Sets', set_name)\n",
    "#     df.to_csv(output_path, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "#     # df.to_csv(output_path, index=False, quoting=csv.QUOTE_NONE, escapechar = ddd)\n",
    "#     print(f\"CSV file saved to {output_path}\")\n",
    "#     return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T14:28:46.274566Z",
     "start_time": "2024-07-13T14:28:46.270263Z"
    }
   },
   "id": "e263a8d9ad0ef2dd",
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def remove_quotes_from_csv(file_path):\n",
    "#     # Read the CSV file and remove quotes\n",
    "#     with open(file_path, 'r', newline='') as infile:\n",
    "#         reader = csv.reader(infile)\n",
    "#         rows = [[cell.replace('\"', '') for cell in row] for row in reader]\n",
    "#     \n",
    "#     # Write the cleaned data back to the CSV file\n",
    "#     with open(file_path, 'w', newline='') as outfile:\n",
    "#         writer = csv.writer(outfile)\n",
    "#         writer.writerows(rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T14:28:50.332291Z",
     "start_time": "2024-07-13T14:28:50.318534Z"
    }
   },
   "id": "35ff43a88bf60c4a",
   "execution_count": 143
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b9b1c34cdf60d0b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for file in os.listdir('Russian/Vocabulary/Quizlet Sets'):\n",
    "#     if file[0] != '.':\n",
    "#         print(file)\n",
    "#         makequizlet_step2('Russian/Vocabulary/Quizlet Sets/' + file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T14:28:51.805219Z",
     "start_time": "2024-07-13T14:28:51.802059Z"
    }
   },
   "id": "f1075c8836d2d749",
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c804ac11b3f56330"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
